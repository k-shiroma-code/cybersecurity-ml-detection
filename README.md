# Cybersecurity Intrusion Detection with Machine Learning

An AI-powered cybersecurity threat detection system achieving 88.6% accuracy with zero false positives, designed for production deployment in enterprise security operations centers (SOCs).

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3%2B-orange)](https://scikit-learn.org)
[![XGBoost](https://img.shields.io/badge/XGBoost-1.7%2B-green)](https://xgboost.readthedocs.io)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ðŸŽ¯ Key Results

- **88.6% Accuracy** - Industry-leading threat detection performance
- **74.6% Attack Detection Rate** - Catches 3 out of 4 cyber attacks  
- **0% False Positive Rate** - Zero false alarms to reduce analyst fatigue
- **54.9% Improvement** over baseline unsupervised methods

## ðŸ“Š Model Performance

| Metric | Value | Impact |
|--------|-------|--------|
| Accuracy | 88.6% | Overall detection performance |
| Attack Precision | 100% | When model says "attack," it's always right |
| Attack Recall | 74.6% | Catches 636 out of 853 real attacks |
| False Alarms | 0 | No wasted analyst time |
| Processing Speed | ~1ms per session | Real-time capable |

## ðŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/cybersecurity-ml-detection.git
cd cybersecurity-ml-detection

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

```python
import pandas as pd
import joblib
from src.model import CyberSecurityDetector

# Load trained model
model = joblib.load('models/cybersecurity_model_production.pkl')

# Load your network session data
data = pd.read_csv('your_network_data.csv')

# Make predictions
predictions, probabilities = model.predict_attacks(data)

# Results: 0 = normal, 1 = attack
print(f"Detected {sum(predictions)} potential attacks")
```

### Training Your Own Model

```python
from src.train_model import train_cybersecurity_model

# Train on your dataset
model, metrics = train_cybersecurity_model(
    data_path='data/cybersecurity_intrusion_data.csv',
    model_type='random_forest',
    save_path='models/my_model.pkl'
)

print(f"Model accuracy: {metrics['accuracy']:.3f}")
```

## ðŸ“ Project Structure

```
cybersecurity-ml-detection/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cybersecurity_intrusion_data.csv    # Training dataset
â”‚   â””â”€â”€ sample_data.csv                      # Example data format
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ cybersecurity_model_production.pkl  # Production-ready model
â”‚   â””â”€â”€ model_comparison_results.json       # Model evaluation results
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb          # Data analysis
â”‚   â”œâ”€â”€ 02_model_development.ipynb         # Model training process
â”‚   â””â”€â”€ 03_threshold_optimization.ipynb    # Performance tuning
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py              # Data cleaning pipeline
â”‚   â”œâ”€â”€ model.py                          # Model classes and prediction
â”‚   â”œâ”€â”€ train_model.py                    # Training script
â”‚   â””â”€â”€ evaluation.py                    # Performance metrics
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_model.py                     # Unit tests
â”‚   â””â”€â”€ test_preprocessing.py             # Data pipeline tests
â”œâ”€â”€ requirements.txt                       # Python dependencies
â”œâ”€â”€ README.md                             # This file
â””â”€â”€ LICENSE                               # MIT License
```

## ðŸ”§ Technical Approach

### Problem Statement
Traditional signature-based intrusion detection systems struggle with:
- High false positive rates (analyst fatigue)
- Inability to detect novel attack patterns
- Manual rule maintenance overhead

### Solution Architecture

1. **Data Preprocessing Pipeline**
   - Handles mixed numeric and categorical features
   - Automated missing value imputation
   - Feature scaling and encoding

2. **Model Selection Process**
   - Tested: Random Forest, XGBoost, Logistic Regression
   - Winner: Random Forest (most stable, zero false positives)
   - 5-fold cross-validation for robust evaluation

3. **Threshold Optimization**
   - Analyzed precision-recall trade-offs
   - Optimized for production deployment (minimal false alarms)

### Why This Approach Works

- **Supervised Learning**: Uses labeled attack data to learn threat patterns
- **Ensemble Method**: Random Forest combines multiple decision trees for robustness
- **Balanced Classes**: Handles 45% attack rate with appropriate class weighting
- **Production Focus**: Optimized for real-world SOC deployment

## ðŸ“ˆ Model Development Journey

### Phase 1: Unsupervised Approach (Failed)
```python
# Initial attempt with Isolation Forest
IsolationForest(contamination=0.45)
# Result: 57.2% accuracy - not production viable
```

### Phase 2: Supervised Learning (Success)
```python
# Winning approach
RandomForestClassifier(
    n_estimators=300,
    class_weight='balanced',
    max_depth=10
)
# Result: 88.6% accuracy with 0% false positives
```

### Phase 3: Threshold Optimization
```python
# Found optimal decision boundary
optimal_threshold = 0.45  # Balances detection vs false alarms
```

## ðŸ› ï¸ Requirements

### Core Dependencies
```
python>=3.8
pandas>=1.5.0
scikit-learn>=1.3.0
xgboost>=1.7.0
numpy>=1.21.0
matplotlib>=3.5.0
seaborn>=0.11.0
```

### Development Dependencies
```
jupyter>=1.0.0
pytest>=7.0.0
black>=22.0.0
flake8>=5.0.0
```

## ðŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest tests/

# Run specific test file
pytest tests/test_model.py -v

# Run with coverage
pytest --cov=src tests/
```

## ðŸ“Š Data Format

Expected input data format:

| Column | Type | Description |
|--------|------|-------------|
| session_id | string | Unique session identifier |
| src_ip | string | Source IP address |
| dst_ip | string | Destination IP address |
| protocol | string | Network protocol (TCP/UDP/ICMP) |
| port | integer | Destination port number |
| bytes_sent | integer | Total bytes transmitted |
| duration | float | Session duration in seconds |
| packet_count | integer | Number of packets |
| attack_detected | integer | Target variable (0=normal, 1=attack) |

## ðŸš€ Production Deployment

### Docker Deployment
```bash
# Build container
docker build -t cybersecurity-ml .

# Run prediction service
docker run -p 8000:8000 cybersecurity-ml
```

### API Endpoint
```python
# POST /predict
{
  "sessions": [
    {
      "src_ip": "192.168.1.100",
      "dst_ip": "10.0.0.1",
      "protocol": "TCP",
      "port": 80,
      "bytes_sent": 1024,
      "duration": 5.2,
      "packet_count": 15
    }
  ]
}

# Response
{
  "predictions": [0],  # 0=normal, 1=attack
  "probabilities": [0.23],
  "model_version": "v1.0"
}
```

## ðŸ“‹ Performance Monitoring

Track these metrics in production:

```python
# Key metrics to monitor
metrics = {
    'daily_accuracy': 0.886,
    'false_positive_rate': 0.000,
    'attack_detection_rate': 0.746,
    'processing_latency_ms': 0.8,
    'model_drift_score': 0.02
}
```






**âš¡ Ready for production deployment with 88.6% accuracy and zero false alarms!**
