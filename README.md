# Cybersecurity Intrusion Detection with Machine Learning

An AI-powered cybersecurity threat detection system achieving 88.6% accuracy with zero false positives, designed for production deployment in enterprise security operations centers (SOCs).

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3%2B-orange)](https://scikit-learn.org)
[![XGBoost](https://img.shields.io/badge/XGBoost-1.7%2B-green)](https://xgboost.readthedocs.io)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ¯ Key Results

- **88.6% Accuracy** - Industry-leading threat detection performance
- **74.6% Attack Detection Rate** - Catches 3 out of 4 cyber attacks  
- **0% False Positive Rate** - Zero false alarms to reduce analyst fatigue
- **54.9% Improvement** over baseline unsupervised methods

## ğŸ“Š Model Performance

| Metric | Value | Impact |
|--------|-------|--------|
| Accuracy | 88.6% | Overall detection performance |
| Attack Precision | 100% | When model says "attack," it's always right |
| Attack Recall | 74.6% | Catches 636 out of 853 real attacks |
| False Alarms | 0 | No wasted analyst time |
| Processing Speed | ~1ms per session | Real-time capable |

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/cybersecurity-ml-detection.git
cd cybersecurity-ml-detection

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

```python
import pandas as pd
import joblib
from src.model import CyberSecurityDetector

# Load trained model
model = joblib.load('models/cybersecurity_model_production.pkl')

# Load your network session data
data = pd.read_csv('your_network_data.csv')

# Make predictions
predictions, probabilities = model.predict_attacks(data)

# Results: 0 = normal, 1 = attack
print(f"Detected {sum(predictions)} potential attacks")
```

### Training Your Own Model

```python
from src.train_model import train_cybersecurity_model

# Train on your dataset
model, metrics = train_cybersecurity_model(
    data_path='data/cybersecurity_intrusion_data.csv',
    model_type='random_forest',
    save_path='models/my_model.pkl'
)

print(f"Model accuracy: {metrics['accuracy']:.3f}")
```

## ğŸ“ Project Structure

```
cybersecurity-ml-detection/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cybersecurity_intrusion_data.csv    # Training dataset
â”‚   â””â”€â”€ sample_data.csv                      # Example data format
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ cybersecurity_model_production.pkl  # Production-ready model
â”‚   â””â”€â”€ model_comparison_results.json       # Model evaluation results
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb          # Data analysis
â”‚   â”œâ”€â”€ 02_model_development.ipynb         # Model training process
â”‚   â””â”€â”€ 03_threshold_optimization.ipynb    # Performance tuning
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py              # Data cleaning pipeline
â”‚   â”œâ”€â”€ model.py                          # Model classes and prediction
â”‚   â”œâ”€â”€ train_model.py                    # Training script
â”‚   â””â”€â”€ evaluation.py                    # Performance metrics
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_model.py                     # Unit tests
â”‚   â””â”€â”€ test_preprocessing.py             # Data pipeline tests
â”œâ”€â”€ requirements.txt                       # Python dependencies
â”œâ”€â”€ README.md                             # This file
â””â”€â”€ LICENSE                               # MIT License
```

## ğŸ”§ Technical Approach

### Problem Statement
Traditional signature-based intrusion detection systems struggle with:
- High false positive rates (analyst fatigue)
- Inability to detect novel attack patterns
- Manual rule maintenance overhead

### Solution Architecture

1. **Data Preprocessing Pipeline**
   - Handles mixed numeric and categorical features
   - Automated missing value imputation
   - Feature scaling and encoding

2. **Model Selection Process**
   - Tested: Random Forest, XGBoost, Logistic Regression
   - Winner: Random Forest (most stable, zero false positives)
   - 5-fold cross-validation for robust evaluation

3. **Threshold Optimization**
   - Analyzed precision-recall trade-offs
   - Optimized for production deployment (minimal false alarms)

### Why This Approach Works

- **Supervised Learning**: Uses labeled attack data to learn threat patterns
- **Ensemble Method**: Random Forest combines multiple decision trees for robustness
- **Balanced Classes**: Handles 45% attack rate with appropriate class weighting
- **Production Focus**: Optimized for real-world SOC deployment

## ğŸ“ˆ Model Development Journey

### Phase 1: Unsupervised Approach (Failed)
```python
# Initial attempt with Isolation Forest
IsolationForest(contamination=0.45)
# Result: 57.2% accuracy - not production viable
```

### Phase 2: Supervised Learning (Success)
```python
# Winning approach
RandomForestClassifier(
    n_estimators=300,
    class_weight='balanced',
    max_depth=10
)
# Result: 88.6% accuracy with 0% false positives
```

### Phase 3: Threshold Optimization
```python
# Found optimal decision boundary
optimal_threshold = 0.45  # Balances detection vs false alarms
```

## ğŸ› ï¸ Requirements

### Core Dependencies
```
python>=3.8
pandas>=1.5.0
scikit-learn>=1.3.0
xgboost>=1.7.0
numpy>=1.21.0
matplotlib>=3.5.0
seaborn>=0.11.0
```

### Development Dependencies
```
jupyter>=1.0.0
pytest>=7.0.0
black>=22.0.0
flake8>=5.0.0
```

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest tests/

# Run specific test file
pytest tests/test_model.py -v

# Run with coverage
pytest --cov=src tests/
```

## ğŸ“Š Data Format

Expected input data format:

| Column | Type | Description |
|--------|------|-------------|
| session_id | string | Unique session identifier |
| src_ip | string | Source IP address |
| dst_ip | string | Destination IP address |
| protocol | string | Network protocol (TCP/UDP/ICMP) |
| port | integer | Destination port number |
| bytes_sent | integer | Total bytes transmitted |
| duration | float | Session duration in seconds |
| packet_count | integer | Number of packets |
| attack_detected | integer | Target variable (0=normal, 1=attack) |

## Network Protocols 
| Protocol | Description | Examples |
|--------|------|-------------|
| TCP  | Connection-oriented network protocol that ensures data delivery, flow control, error detection/correction, and full duplex communication | HTTP/HTTPS, FTP, POP/SMTP/IMAP |
| UDP  | Connectionless network protocol with a focus on speed rather than reliability, lightweight, and used for real-time communication, requires less overhead | VoIP, Streaming, Online Games, DNS |
| ICMP | Error reporting and diagnostic network protocol focused on ensuring network connectivity among devices | Ping, Tracert |

## ğŸš€ Production Deployment

### Docker Deployment
```bash
# Build container
docker build -t cybersecurity-ml .

# Run prediction service
docker run -p 8000:8000 cybersecurity-ml
```

### API Endpoint
```python
# POST /predict
{
  "sessions": [
    {
      "src_ip": "192.168.1.100",
      "dst_ip": "10.0.0.1",
      "protocol": "TCP",
      "port": 80,
      "bytes_sent": 1024,
      "duration": 5.2,
      "packet_count": 15
    }
  ]
}

# Response
{
  "predictions": [0],  # 0=normal, 1=attack
  "probabilities": [0.23],
  "model_version": "v1.0"
}
```

## ğŸ“‹ Performance Monitoring

Track these metrics in production:

```python
# Key metrics to monitor
metrics = {
    'daily_accuracy': 0.886,
    'false_positive_rate': 0.000,
    'attack_detection_rate': 0.746,
    'processing_latency_ms': 0.8,
    'model_drift_score': 0.02
}
```

## ğŸ”„ Model Retraining

Schedule regular retraining:

```bash
# Weekly model evaluation
python src/evaluate_drift.py --data data/new_week_data.csv

# Monthly retraining
python src/train_model.py --retrain --data data/monthly_data.csv
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -am 'Add new feature'`)
4. Push to branch (`git push origin feature/improvement`)
5. Create Pull Request

### Development Setup
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Set up pre-commit hooks
pre-commit install

# Run code formatting
black src/ tests/
flake8 src/ tests/
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Dataset: [Cybersecurity Intrusion Dataset](link-to-dataset)
- Inspiration: NIST Cybersecurity Framework
- Community: Thanks to the cybersecurity ML research community

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/cybersecurity-ml-detection/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/cybersecurity-ml-detection/discussions)
- **Documentation**: [Wiki](https://github.com/yourusername/cybersecurity-ml-detection/wiki)

## ğŸ“Š Citation

If you use this work in research, please cite:

```bibtex
@software{cybersecurity_ml_detection,
  title={Cybersecurity Intrusion Detection with Machine Learning},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/cybersecurity-ml-detection}
}
```

---

**âš¡ Ready for production deployment with 88.6% accuracy and zero false alarms!**
